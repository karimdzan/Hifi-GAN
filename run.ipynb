{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Jf93GyLIAOZ"
      },
      "outputs": [],
      "source": [
        "!cd hw_ars_draft && python3 train.py --config hw_asr/configs/conformer_aug.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TM1pMYRWU5ai",
        "outputId": "0140e3f5-6258-4ff5-a4f1-5350a40feaec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
            "  torchaudio.set_audio_backend(\"soundfile\")\n",
            "['^', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ']\n",
            "Alphabet determined to be of regular style.\n",
            "1 (0.0%) records are longer then 20.0 seconds. Excluding them.\n",
            "13243 (46.4%) records are longer then 200 characters. Excluding them.\n",
            "Filtered 13243(46.4%) records  from dataset\n",
            "17 (0.0%) records are longer then 20.0 seconds. Excluding them.\n",
            "48340 (46.5%) records are longer then 200 characters. Excluding them.\n",
            "Filtered 48340(46.5%) records  from dataset\n",
            "37 (0.0%) records are longer then 20.0 seconds. Excluding them.\n",
            "56078 (37.7%) records are longer then 200 characters. Excluding them.\n",
            "Filtered 56078(37.7%) records  from dataset\n",
            "92 (3.5%) records are longer then 20.0 seconds. Excluding them.\n",
            "334 (12.7%) records are longer then 200 characters. Excluding them.\n",
            "Filtered 335(12.8%) records  from dataset\n",
            "46 (1.6%) records are longer then 20.0 seconds. Excluding them.\n",
            "240 (8.2%) records are longer then 200 characters. Excluding them.\n",
            "Filtered 240(8.2%) records  from dataset\n",
            "Conformer(\n",
            "  (layers): ModuleList(\n",
            "    (0-11): 12 x ConformerBlock(\n",
            "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (ff1): FeedForward(\n",
            "        (net): Sequential(\n",
            "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (1): Linear(in_features=128, out_features=512, bias=True)\n",
            "          (2): Swish()\n",
            "          (3): Dropout(p=0.0, inplace=False)\n",
            "          (4): Linear(in_features=512, out_features=128, bias=True)\n",
            "          (5): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (attn): MultiHeadedSelfAttentionModule(\n",
            "        (positional_encoding): PositionalEncoding()\n",
            "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (attention): RelativeMultiHeadAttention(\n",
            "          (query_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (key_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (value_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (pos_proj): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (conv): ConformerConvModule(\n",
            "        (net): Sequential(\n",
            "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (1): Rearrange('b n c -> b c n')\n",
            "          (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
            "          (3): GLU()\n",
            "          (4): DepthWiseConv1d(\n",
            "            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), groups=256)\n",
            "          )\n",
            "          (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (6): Swish()\n",
            "          (7): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
            "          (8): Rearrange('b c n -> b n c')\n",
            "          (9): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (ff2): FeedForward(\n",
            "        (net): Sequential(\n",
            "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (1): Linear(in_features=128, out_features=512, bias=True)\n",
            "          (2): Swish()\n",
            "          (3): Dropout(p=0.0, inplace=False)\n",
            "          (4): Linear(in_features=512, out_features=128, bias=True)\n",
            "          (5): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv_subsample): Conv2dSubsampling(\n",
            "    (sequential): Sequential(\n",
            "      (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(2, 2))\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (input_proj): Sequential(\n",
            "    (0): Linear(in_features=3968, out_features=128, bias=True)\n",
            "    (1): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=128, out_features=28, bias=False)\n",
            ")\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkarimdzan\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.12\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/hw_ars_draft/wandb/run-20231026_204935-6l7uspfp\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfragrant-energy-42\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/karimdzan/asr_project\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/karimdzan/asr_project/runs/6l7uspfp\u001b[0m\n",
            "Loading checkpoint: /content/hw_ars_draft/saved/models/conformer/1026_194905/model_best.pth ...\n",
            "Checkpoint loaded. Resume training from epoch 115\n",
            "train:   0% 0/500 [00:00<?, ?it/s]Train Epoch: 114 [0/500 (0%)] Loss: 0.493127\n",
            "train:  10% 50/500 [00:44<05:58,  1.25it/s]Train Epoch: 114 [50/500 (10%)] Loss: 0.447313\n",
            "train:  20% 100/500 [01:25<05:10,  1.29it/s]Train Epoch: 114 [100/500 (20%)] Loss: 0.423497\n",
            "train:  30% 150/500 [02:06<04:39,  1.25it/s]Train Epoch: 114 [150/500 (30%)] Loss: 0.430146\n",
            "train:  40% 200/500 [02:47<03:57,  1.27it/s]Train Epoch: 114 [200/500 (40%)] Loss: 0.515342\n",
            "train:  50% 250/500 [03:28<03:15,  1.28it/s]Train Epoch: 114 [250/500 (50%)] Loss: 0.501653\n",
            "train:  60% 300/500 [04:10<02:43,  1.22it/s]Train Epoch: 114 [300/500 (60%)] Loss: 0.463706\n",
            "train:  70% 350/500 [04:52<02:06,  1.19it/s]Train Epoch: 114 [350/500 (70%)] Loss: 0.492027\n",
            "train:  80% 400/500 [05:34<01:22,  1.21it/s]Train Epoch: 114 [400/500 (80%)] Loss: 0.458608\n",
            "train:  90% 450/500 [06:16<00:44,  1.13it/s]Train Epoch: 114 [450/500 (90%)] Loss: 0.458870\n",
            "train: 100% 500/500 [06:58<00:00,  1.24it/s]Train Epoch: 114 [500/500 (100%)] Loss: 0.456327\n",
            "train: 100% 500/500 [07:00<00:00,  1.19it/s]\n",
            "val: 100% 78/78 [00:15<00:00,  5.13it/s]\n",
            "    epoch          : 115\n",
            "    loss           : 0.47209475457668304\n",
            "    grad norm      : 1.2208499908447266\n",
            "    WER (argmax)   : 0.3796991703082275\n",
            "    CER (argmax)   : 0.13024740266817364\n",
            "    val_loss       : 0.6749590046894856\n",
            "    val_WER (argmax): 0.47050709847106037\n",
            "    val_CER (argmax): 0.17632727301923312\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/500 [00:00<?, ?it/s]Train Epoch: 115 [0/500 (0%)] Loss: 0.479496\n",
            "train:   1% 5/500 [00:05<08:35,  1.04s/it]\n",
            "Saving model on keyboard interrupt\n",
            "Saving checkpoint: saved/models/conformer/1026_204932/checkpoint-epoch116.pth ...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/hw_ars_draft/train.py\", line 107, in <module>\n",
            "    main(config)\n",
            "  File \"/content/hw_ars_draft/train.py\", line 71, in main\n",
            "    trainer.train()\n",
            "  File \"/content/hw_ars_draft/hw_asr/base/base_trainer.py\", line 73, in train\n",
            "    raise e\n",
            "  File \"/content/hw_ars_draft/hw_asr/base/base_trainer.py\", line 69, in train\n",
            "    self._train_process()\n",
            "  File \"/content/hw_ars_draft/hw_asr/base/base_trainer.py\", line 82, in _train_process\n",
            "    result = self._train_epoch(epoch - 1)\n",
            "  File \"/content/hw_ars_draft/hw_asr/trainer/trainer.py\", line 94, in _train_epoch\n",
            "    batch = self.process_batch(\n",
            "  File \"/content/hw_ars_draft/hw_asr/trainer/trainer.py\", line 140, in process_batch\n",
            "    batch = self.move_batch_to_device(batch, self.device)\n",
            "  File \"/content/hw_ars_draft/hw_asr/trainer/trainer.py\", line 71, in move_batch_to_device\n",
            "    batch[tensor_for_gpu] = batch[tensor_for_gpu].to(device)\n",
            "KeyboardInterrupt\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 255).\u001b[0m Press Control-C to abort syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  CER (argmax)_train ‚ñà‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÖ‚ñÅ‚ñÜ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    CER (argmax)_val ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  WER (argmax)_train ‚ñà‚ñÅ‚ñÇ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÑ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    WER (argmax)_val ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              epoch_ ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           epoch_val ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     grad norm_train ‚ñÑ‚ñá‚ñÅ‚ñà‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÅ‚ñÇ‚ñÉ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: learning rate_train ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          loss_train ‚ñà‚ñÅ‚ñÅ‚ñÜ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÖ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            loss_val ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: steps_per_sec_train ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   steps_per_sec_val ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  CER (argmax)_train 0.13163\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    CER (argmax)_val 0.17633\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  WER (argmax)_train 0.38562\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    WER (argmax)_val 0.47051\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              epoch_ 114\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           epoch_val 115\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     grad norm_train 1.18343\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: learning rate_train 1e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          loss_train 0.4795\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            loss_val 0.67496\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: steps_per_sec_train 0.37326\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   steps_per_sec_val 0.06183\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mfragrant-energy-42\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/karimdzan/asr_project/runs/6l7uspfp\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ô∏è‚ö° View job at \u001b[34m\u001b[4mhttps://wandb.ai/karimdzan/asr_project/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwODg5MDkwMw==/version_details/v47\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 26 media file(s), 15 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231026_204935-6l7uspfp/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!cd hw_ars_draft && python3 train.py -r /content/hw_ars_draft/saved/models/conformer/1026_194905/model_best.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fz9YsvkDNGA4"
      },
      "outputs": [],
      "source": [
        "# !wget https://www.openslr.org/resources/11/3-gram.arpa.gz --no-check-certificate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4N7H-c1lP2ME"
      },
      "outputs": [],
      "source": [
        "# !gzip -d 3-gram.arpa.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqGxYAc8OP-N",
        "outputId": "83827552-f26f-47bc-ccff-e31156adf460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
            "  torchaudio.set_audio_backend(\"soundfile\")\n",
            "['^', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ']\n",
            "Loading the LM will be faster if you build a binary file.\n",
            "Reading /content/3-gram.arpa\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Using arpa instead of binary LM file, decoder instantiation might be slow.\n",
            "Alphabet determined to be of regular style.\n",
            "Conformer(\n",
            "  (layers): ModuleList(\n",
            "    (0-11): 12 x ConformerBlock(\n",
            "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (ff1): FeedForward(\n",
            "        (net): Sequential(\n",
            "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (1): Linear(in_features=128, out_features=512, bias=True)\n",
            "          (2): Swish()\n",
            "          (3): Dropout(p=0.0, inplace=False)\n",
            "          (4): Linear(in_features=512, out_features=128, bias=True)\n",
            "          (5): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (attn): MultiHeadedSelfAttentionModule(\n",
            "        (positional_encoding): PositionalEncoding()\n",
            "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (attention): RelativeMultiHeadAttention(\n",
            "          (query_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (key_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (value_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (pos_proj): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (conv): ConformerConvModule(\n",
            "        (net): Sequential(\n",
            "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (1): Rearrange('b n c -> b c n')\n",
            "          (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
            "          (3): GLU()\n",
            "          (4): DepthWiseConv1d(\n",
            "            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), groups=256)\n",
            "          )\n",
            "          (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (6): Swish()\n",
            "          (7): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
            "          (8): Rearrange('b c n -> b n c')\n",
            "          (9): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (ff2): FeedForward(\n",
            "        (net): Sequential(\n",
            "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (1): Linear(in_features=128, out_features=512, bias=True)\n",
            "          (2): Swish()\n",
            "          (3): Dropout(p=0.0, inplace=False)\n",
            "          (4): Linear(in_features=512, out_features=128, bias=True)\n",
            "          (5): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv_subsample): Conv2dSubsampling(\n",
            "    (sequential): Sequential(\n",
            "      (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(2, 2))\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (input_proj): Sequential(\n",
            "    (0): Linear(in_features=3968, out_features=128, bias=True)\n",
            "    (1): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=128, out_features=28, bias=False)\n",
            ")\n",
            "Loading checkpoint: /content/hw_ars_draft/saved/models/conformer/1026_194905/model_best.pth ...\n",
            "100% 41/41 [05:10<00:00,  7.57s/it]\n",
            "WER_argmax: 0.3779\n",
            "WER_beam_search: 0.2011\n",
            "CER_argmax: 0.1218\n",
            "CER_beam_search: 0.0881\n"
          ]
        }
      ],
      "source": [
        "!cd hw_ars_draft && python3 test.py \\\n",
        "    --config hw_asr/configs/conformer_evaluate_test_clean.json \\\n",
        "    --resume /content/hw_ars_draft/saved/models/conformer/1026_194905/model_best.pth \\\n",
        "    --batch-size 64 \\\n",
        "    --jobs 4 \\\n",
        "    --beam-size 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMHWFCBsOmdV",
        "outputId": "15adf594-6975-4cbf-9abc-eae379375c38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
            "  torchaudio.set_audio_backend(\"soundfile\")\n",
            "['^', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ']\n",
            "Loading the LM will be faster if you build a binary file.\n",
            "Reading /content/3-gram.arpa\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "Using arpa instead of binary LM file, decoder instantiation might be slow.\n",
            "Alphabet determined to be of regular style.\n",
            "Conformer(\n",
            "  (layers): ModuleList(\n",
            "    (0-11): 12 x ConformerBlock(\n",
            "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (ff1): FeedForward(\n",
            "        (net): Sequential(\n",
            "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (1): Linear(in_features=128, out_features=512, bias=True)\n",
            "          (2): Swish()\n",
            "          (3): Dropout(p=0.0, inplace=False)\n",
            "          (4): Linear(in_features=512, out_features=128, bias=True)\n",
            "          (5): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (attn): MultiHeadedSelfAttentionModule(\n",
            "        (positional_encoding): PositionalEncoding()\n",
            "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (attention): RelativeMultiHeadAttention(\n",
            "          (query_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (key_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (value_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "          (pos_proj): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (conv): ConformerConvModule(\n",
            "        (net): Sequential(\n",
            "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (1): Rearrange('b n c -> b c n')\n",
            "          (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
            "          (3): GLU()\n",
            "          (4): DepthWiseConv1d(\n",
            "            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), groups=256)\n",
            "          )\n",
            "          (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (6): Swish()\n",
            "          (7): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
            "          (8): Rearrange('b c n -> b n c')\n",
            "          (9): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (ff2): FeedForward(\n",
            "        (net): Sequential(\n",
            "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (1): Linear(in_features=128, out_features=512, bias=True)\n",
            "          (2): Swish()\n",
            "          (3): Dropout(p=0.0, inplace=False)\n",
            "          (4): Linear(in_features=512, out_features=128, bias=True)\n",
            "          (5): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv_subsample): Conv2dSubsampling(\n",
            "    (sequential): Sequential(\n",
            "      (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(2, 2))\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
            "      (3): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (input_proj): Sequential(\n",
            "    (0): Linear(in_features=3968, out_features=128, bias=True)\n",
            "    (1): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=128, out_features=28, bias=False)\n",
            ")\n",
            "Loading checkpoint: saved/models/conformer/finetune/model_best.pth ...\n",
            "100% 46/46 [08:54<00:00, 11.61s/it]\n",
            "WER_argmax: 0.5747\n",
            "WER_beam_search: 0.3991\n",
            "CER_argmax: 0.2337\n",
            "CER_beam_search: 0.2078\n"
          ]
        }
      ],
      "source": [
        "!cd hw_ars_draft && python3 test.py \\\n",
        "    --config hw_asr/configs/conformer_evaluate_test_other.json \\\n",
        "    --resume saved/models/conformer/finetune/model_best.pth \\\n",
        "    --batch-size 64 \\\n",
        "    --jobs 4 \\\n",
        "    --beam-size 100"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}